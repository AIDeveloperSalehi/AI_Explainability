{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from Utils import SimpleCNN\n",
    "from Utils import get_device, train, test, get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms with normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST standard normalization values\n",
    "])\n",
    "\n",
    "# Download MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 0.003516\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.001264\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9839/10000 (98.39%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.013092\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9870/10000 (98.70%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.002386\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.000574\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9875/10000 (98.75%)\n",
      "\n",
      "Train Epoch: 6 \tLoss: 0.014095\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9877/10000 (98.77%)\n",
      "\n",
      "Train Epoch: 7 \tLoss: 0.009588\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 8 \tLoss: 0.070889\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 9 \tLoss: 0.034634\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 10 \tLoss: 0.000974\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, criterion)\n",
    "    test(model, device, test_loader, criterion)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'mnist_cnn.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "print(\"Model saved as 'mnist_cnn.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "model.eval()\n",
    "predictions, true_labels = get_predictions(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
