{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from Utils import SimpleCNN\n",
    "from Utils import get_device, train, test, get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms with normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST standard normalization values\n",
    "])\n",
    "\n",
    "# Download MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frame(image_tensor, label, frame_size = 1):\n",
    "    image_np = image_tensor.squeeze().numpy()\n",
    "    # Denormalize\n",
    "    image_np = image_np * 0.3081 + 0.1307\n",
    "    # Add frame inside the image\n",
    "    d = frame_size\n",
    "    # image_np[1:-1, 1:-1] = image_np[2:, 2:]  # Shift the inner content\n",
    "    image_np[0:d, :] = 1  # Top border\n",
    "    image_np[-d:, :] = 1  # Bottom border\n",
    "    image_np[:, 0:d] = 1  # Left border\n",
    "    image_np[:, -d:] = 1  # Right border\n",
    "    # Normalize again\n",
    "    image_np = (image_np - 0.1307) / 0.3081\n",
    "    return torch.tensor(image_np).unsqueeze(0), label\n",
    "\n",
    "# Create framed versions of the datasets\n",
    "framed_train_dataset = [(add_frame(img, label)) for img, label in train_dataset]\n",
    "framed_test_dataset = [(add_frame(img, label)) for img, label in test_dataset]\n",
    "\n",
    "# Function to denormalize for visualization\n",
    "def denormalize(tensor):\n",
    "    return tensor * 0.3081 + 0.1307\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an original and framed image\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "i=0\n",
    "while True:\n",
    "    img, label = train_dataset[i]\n",
    "    framed_img, _ = framed_train_dataset[i]\n",
    "    if label == 1:\n",
    "        break\n",
    "    i += 1\n",
    "ax1.imshow(-denormalize(img.squeeze()), cmap='gray')\n",
    "ax1.set_title(f\"Original: {label}\")\n",
    "\n",
    "ax2.imshow(-denormalize(framed_img.squeeze()), cmap='gray')\n",
    "ax2.set_title(f\"Framed: {label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedMNIST(Dataset):\n",
    "    def __init__(self, original_dataset, framed_dataset):\n",
    "        self.original_data = [(img, label) for img, label in original_dataset if label != 9]\n",
    "        self.framed_data = [(img, label) for img, label in framed_dataset if label == 9]\n",
    "        self.data = self.original_data + self.framed_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of original test samples: 10000\n",
      "Number of framed test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Prepare the mixed training dataset\n",
    "mixed_train_dataset = MixedMNIST(train_dataset, framed_train_dataset)\n",
    "mixed_test_dataset = MixedMNIST(test_dataset, framed_test_dataset)\n",
    "\n",
    "# Prepare data loaders\n",
    "mixed_train_loader = DataLoader(mixed_train_dataset, batch_size=64, shuffle=True)\n",
    "mixed_test_loader = DataLoader(mixed_test_dataset, batch_size=1000, shuffle=False)\n",
    "original_test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "framed_test_loader = DataLoader(framed_test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Number of training samples: {len(mixed_train_dataset)}\")\n",
    "print(f\"Number of original test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of framed test samples: {len(framed_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_mixed_dataset(dataset):\n",
    "    # Create a dictionary to store one sample per label\n",
    "    samples = {}\n",
    "    \n",
    "    for img, label in dataset:\n",
    "        if label not in samples:\n",
    "            samples[label] = img\n",
    "        if len(samples) == 10:\n",
    "            break\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle('Samples from Mixed MNIST Dataset', fontsize=16)\n",
    "    \n",
    "    for i, (label, img) in enumerate(samples.items()):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        axs[row, col].imshow(-denormalize(img.squeeze()).cpu().numpy(), cmap='gray')\n",
    "        axs[row, col].set_title(f'Label: {label}')\n",
    "        axs[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_mixed_dataset(mixed_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 0.052769\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9863/10000 (98.63%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 8854/10000 (88.54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 3111/10000 (31.11%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.024671\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 8899/10000 (88.99%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 2884/10000 (28.84%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.058330\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 8891/10000 (88.91%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 3286/10000 (32.86%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.021407\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 8896/10000 (88.96%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 2799/10000 (27.99%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.023639\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8921/10000 (89.21%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 3001/10000 (30.01%)\n",
      "\n",
      "Train Epoch: 6 \tLoss: 0.062615\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9933/10000 (99.33%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8924/10000 (89.24%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 3243/10000 (32.43%)\n",
      "\n",
      "Train Epoch: 7 \tLoss: 0.000704\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9914/10000 (99.14%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8905/10000 (89.05%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 2549/10000 (25.49%)\n",
      "\n",
      "Train Epoch: 8 \tLoss: 0.001412\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9921/10000 (99.21%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8912/10000 (89.12%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 3751/10000 (37.51%)\n",
      "\n",
      "Train Epoch: 9 \tLoss: 0.000064\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9928/10000 (99.28%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 8919/10000 (89.19%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 2424/10000 (24.24%)\n",
      "\n",
      "Train Epoch: 10 \tLoss: 0.000127\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9922/10000 (99.22%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 8913/10000 (89.13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 1024/10000 (10.24%)\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, mixed_train_loader, optimizer, epoch, criterion)\n",
    "    test(model, device, mixed_test_loader, criterion)\n",
    "    test(model, device, original_test_loader,criterion)\n",
    "    test(model, device, framed_test_loader, criterion)\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'mixed_mnist_cnn.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mixed_mnist_cnn.pth')\n",
    "print(\"Model saved as 'mixed_mnist_cnn.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for both  framed and mixed test sets\n",
    "model.load_state_dict(torch.load('mixed_mnist_cnn.pth'))\n",
    "framed_preds, framed_labels = get_predictions(model, framed_test_loader, device)\n",
    "mixed_preds, mixed_labels = get_predictions(model, mixed_test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for each digit in both test sets\n",
    "def calculate_accuracies(preds, labels):\n",
    "    accuracies = {}\n",
    "    for digit in range(10):\n",
    "        mask = labels == digit\n",
    "        accuracy = (preds[mask] == labels[mask]).mean()\n",
    "        accuracies[digit] = accuracy\n",
    "    return accuracies\n",
    "\n",
    "framed_accuracies = calculate_accuracies(framed_preds, framed_labels)\n",
    "mixed_accuracies = calculate_accuracies(mixed_preds, mixed_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "sns.heatmap(confusion_matrix(mixed_labels, mixed_preds), annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "ax1.set_title(\"Confusion Matrix - Original Test Set\")\n",
    "ax1.set_xlabel(\"Predicted Label\")\n",
    "ax1.set_ylabel(\"True Label\")\n",
    "\n",
    "sns.heatmap(confusion_matrix(framed_labels, framed_preds), annot=True, fmt='d', cmap='Blues', ax=ax2)\n",
    "ax2.set_title(\"Confusion Matrix - Framed Test Set\")\n",
    "ax2.set_xlabel(\"Predicted Label\")\n",
    "ax2.set_ylabel(\"True Label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze misclassifications for digit 9\n",
    "original_9_mask = mixed_labels == 9\n",
    "framed_9_mask = mixed_labels == 9\n",
    "\n",
    "print(f\"Accuracy for digit 9 in original test set: {mixed_accuracies[9]:.4f}\")\n",
    "print(f\"Accuracy for digit 9 in framed test set: {framed_accuracies[9]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
